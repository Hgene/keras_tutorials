{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor-board examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gene\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 3s 167us/step - loss: 0.2106 - acc: 0.1060 - val_loss: 1.3942 - val_acc: 0.1552\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 4s 200us/step - loss: 0.2078 - acc: 0.0827 - val_loss: 1.3608 - val_acc: 0.1574\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 4s 197us/step - loss: 0.1987 - acc: 0.0757 - val_loss: 1.4238 - val_acc: 0.1422\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 4s 184us/step - loss: 0.2024 - acc: 0.0692 - val_loss: 1.5062 - val_acc: 0.1258\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 4s 189us/step - loss: 0.1950 - acc: 0.0589 - val_loss: 1.4851 - val_acc: 0.1194\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 4s 185us/step - loss: 0.2004 - acc: 0.0554 - val_loss: 1.5281 - val_acc: 0.1146\n",
      "WARNING:tensorflow:From C:\\Users\\Gene\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 4s 182us/step - loss: 0.1906 - acc: 0.0449 - val_loss: 1.6597 - val_acc: 0.1132\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1985 - acc: 0.0386 - val_loss: 1.6701 - val_acc: 0.0960\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 4s 190us/step - loss: 0.1978 - acc: 0.0379 - val_loss: 1.6659 - val_acc: 0.1066\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.1976 - acc: 0.0349 - val_loss: 1.6580 - val_acc: 0.0918\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 4s 185us/step - loss: 0.2012 - acc: 0.0330 - val_loss: 1.6591 - val_acc: 0.0886\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 4s 197us/step - loss: 0.1986 - acc: 0.0305 - val_loss: 1.6769 - val_acc: 0.0882\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 4s 176us/step - loss: 0.1965 - acc: 0.0246 - val_loss: 1.6858 - val_acc: 0.0812\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 4s 224us/step - loss: 0.1988 - acc: 0.0257 - val_loss: 1.8187 - val_acc: 0.0836\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.1922 - acc: 0.0218 - val_loss: 2.1926 - val_acc: 0.0708\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 3s 147us/step - loss: 0.1981 - acc: 0.0195 - val_loss: 1.6870 - val_acc: 0.0744\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 3s 153us/step - loss: 0.1979 - acc: 0.0180 - val_loss: 1.7499 - val_acc: 0.0688\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 3s 150us/step - loss: 0.1949 - acc: 0.0197 - val_loss: 1.7605 - val_acc: 0.0638\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.1933 - acc: 0.0207 - val_loss: 1.7264 - val_acc: 0.0690\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.2031 - acc: 0.0199 - val_loss: 1.7445 - val_acc: 0.0736\n"
     ]
    }
   ],
   "source": [
    "callbacks=[\n",
    "    keras.callbacks.TensorBoard(log_dir='./my_log_dir',\n",
    "                                histogram_freq=1, \n",
    "                                embeddings_freq=1,\n",
    "                                embeddings_data= np.arange(0, max_len).reshape((1, max_len)),\n",
    "                               )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor-gpu",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
